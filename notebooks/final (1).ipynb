{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4DHHyUGwuLo",
        "outputId": "384a72ee-8301-4c98-c4da-d65b3ca5e314"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -uq \"/content/drive/MyDrive/mini_proj/audio.zip\" -d \"/content/audio\"\n",
        "!unzip -uq \"/content/drive/MyDrive/mini_proj/video.zip\" -d \"/content/video\""
      ],
      "metadata": {
        "id": "18OiiH-KxFnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/audio\"\n",
        "!ls \"/content/video\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYDedwuLxIa-",
        "outputId": "7e203dce-a0a0-4947-84e2-802a0eadde57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actor_01  Actor_06  Actor_11  Actor_16\tActor_21\n",
            "Actor_02  Actor_07  Actor_12  Actor_17\tActor_22\n",
            "Actor_03  Actor_08  Actor_13  Actor_18\tActor_23\n",
            "Actor_04  Actor_09  Actor_14  Actor_19\tActor_24\n",
            "Actor_05  Actor_10  Actor_15  Actor_20\taudio_speech_actors_01-24\n",
            "'Real Life Violence Dataset'  'real life violence situations'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AUDIO MODEL**"
      ],
      "metadata": {
        "id": "elZqE9VozqEg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Install and Import Required Libraries"
      ],
      "metadata": {
        "id": "s4HxL3P0zomM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa\n",
        "!pip install tensorflow\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YynEpQOUz0gU",
        "outputId": "29723293-2793-4ef3-95fc-9afbf49525d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.14.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Define Feature Extraction Function"
      ],
      "metadata": {
        "id": "6vO0kY8xz6Pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features_cnn(file_path, max_pad_len=130):\n",
        "    try:\n",
        "        audio, sr = librosa.load(file_path, duration=3, offset=0.5)\n",
        "        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
        "        if mfcc.shape[1] < max_pad_len:\n",
        "            pad_width = max_pad_len - mfcc.shape[1]\n",
        "            mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "        else:\n",
        "            mfcc = mfcc[:, :max_pad_len]\n",
        "        return mfcc\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {file_path} - {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "RKJLLnLAz85s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Load Data and Extract Features"
      ],
      "metadata": {
        "id": "zEvVLErbz_Dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "labels = []\n",
        "\n",
        "RAVDESS_PATH = '/content/audio'  # Make sure your dataset is here\n",
        "\n",
        "for root, _, files in os.walk(RAVDESS_PATH):\n",
        "    for file in files:\n",
        "        if file.endswith('.wav'):\n",
        "            path = os.path.join(root, file)\n",
        "            label = int(file.split('-')[2])  # Emotion label\n",
        "            features = extract_features_cnn(path)\n",
        "            if features is not None:\n",
        "                data.append(features)\n",
        "                labels.append(label)\n",
        "\n",
        "X = np.array(data)\n",
        "y = np.array(labels)\n",
        "X = X[..., np.newaxis]  # Add channel dimension for CNN\n"
      ],
      "metadata": {
        "id": "1KJPNyyk0Bkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Encode Labels and Split Data"
      ],
      "metadata": {
        "id": "czuNwOO20D69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y_encoded = to_categorical(le.fit_transform(y))  # One-hot encode\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "q_AGKNUu0GBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Build CNN Model"
      ],
      "metadata": {
        "id": "h1i5JEKU0Ihj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(40, 130, 1)),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(y_encoded.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "model_cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_cnn.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "ncl_E4xR0Kq0",
        "outputId": "8e1d8584-e505-43a9-8764-2bc2ce398fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_15\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_15\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_28 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_45 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_29 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_46 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_15 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15872\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m2,031,744\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_47 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m1,032\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15872</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,031,744</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,051,592\u001b[0m (7.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,051,592</span> (7.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,051,592\u001b[0m (7.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,051,592</span> (7.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Train the Model"
      ],
      "metadata": {
        "id": "ZwWTCT650M-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_cnn.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUGHNj420RGn",
        "outputId": "1adfd04a-535f-4650-b6bf-0b4a23200d3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.1594 - loss: 13.3024 - val_accuracy: 0.2205 - val_loss: 2.0475\n",
            "Epoch 2/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2278 - loss: 1.9815 - val_accuracy: 0.2656 - val_loss: 1.8615\n",
            "Epoch 3/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2803 - loss: 1.8179 - val_accuracy: 0.3003 - val_loss: 1.7854\n",
            "Epoch 4/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3538 - loss: 1.7098 - val_accuracy: 0.3854 - val_loss: 1.6490\n",
            "Epoch 5/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4141 - loss: 1.5430 - val_accuracy: 0.4826 - val_loss: 1.4592\n",
            "Epoch 6/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5101 - loss: 1.3456 - val_accuracy: 0.5243 - val_loss: 1.3501\n",
            "Epoch 7/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5544 - loss: 1.2255 - val_accuracy: 0.5747 - val_loss: 1.1929\n",
            "Epoch 8/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5944 - loss: 1.0640 - val_accuracy: 0.6840 - val_loss: 0.9605\n",
            "Epoch 9/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6924 - loss: 0.8354 - val_accuracy: 0.7309 - val_loss: 0.7959\n",
            "Epoch 10/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7212 - loss: 0.7732 - val_accuracy: 0.7622 - val_loss: 0.7329\n",
            "Epoch 11/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7496 - loss: 0.6574 - val_accuracy: 0.8003 - val_loss: 0.6498\n",
            "Epoch 12/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7993 - loss: 0.5641 - val_accuracy: 0.7969 - val_loss: 0.5766\n",
            "Epoch 13/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8261 - loss: 0.4989 - val_accuracy: 0.8333 - val_loss: 0.5744\n",
            "Epoch 14/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8428 - loss: 0.4355 - val_accuracy: 0.8576 - val_loss: 0.4808\n",
            "Epoch 15/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8500 - loss: 0.4284 - val_accuracy: 0.8646 - val_loss: 0.4752\n",
            "Epoch 16/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8529 - loss: 0.3949 - val_accuracy: 0.8576 - val_loss: 0.5839\n",
            "Epoch 17/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8794 - loss: 0.3481 - val_accuracy: 0.8750 - val_loss: 0.4768\n",
            "Epoch 18/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8820 - loss: 0.3179 - val_accuracy: 0.8889 - val_loss: 0.4562\n",
            "Epoch 19/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9008 - loss: 0.2562 - val_accuracy: 0.8906 - val_loss: 0.4849\n",
            "Epoch 20/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9091 - loss: 0.2595 - val_accuracy: 0.8872 - val_loss: 0.4623\n",
            "Epoch 21/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9080 - loss: 0.2431 - val_accuracy: 0.8924 - val_loss: 0.4416\n",
            "Epoch 22/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9064 - loss: 0.2436 - val_accuracy: 0.9028 - val_loss: 0.4287\n",
            "Epoch 23/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9229 - loss: 0.2184 - val_accuracy: 0.8993 - val_loss: 0.4482\n",
            "Epoch 24/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9185 - loss: 0.2386 - val_accuracy: 0.8854 - val_loss: 0.4585\n",
            "Epoch 25/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9200 - loss: 0.2200 - val_accuracy: 0.8958 - val_loss: 0.4640\n",
            "Epoch 26/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9393 - loss: 0.1734 - val_accuracy: 0.8889 - val_loss: 0.4987\n",
            "Epoch 27/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9368 - loss: 0.1583 - val_accuracy: 0.9010 - val_loss: 0.4642\n",
            "Epoch 28/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9263 - loss: 0.1966 - val_accuracy: 0.8958 - val_loss: 0.5258\n",
            "Epoch 29/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9266 - loss: 0.2081 - val_accuracy: 0.9097 - val_loss: 0.5076\n",
            "Epoch 30/30\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9516 - loss: 0.1656 - val_accuracy: 0.8924 - val_loss: 0.4805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Get predicted classes for train and test\n",
        "y_train_pred = model_cnn.predict(X_train)\n",
        "y_test_pred = model_cnn.predict(X_test)\n",
        "\n",
        "# Convert one-hot predictions and true values to class labels\n",
        "y_train_pred_labels = np.argmax(y_train_pred, axis=1)\n",
        "y_test_pred_labels = np.argmax(y_test_pred, axis=1)\n",
        "y_train_true_labels = np.argmax(y_train, axis=1)\n",
        "y_test_true_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Classification report for test set\n",
        "print(\"🔍 Classification Report (Test Set):\")\n",
        "print(classification_report(y_test_true_labels, y_test_pred_labels))\n",
        "\n",
        "# Accuracy\n",
        "train_accuracy = accuracy_score(y_train_true_labels, y_train_pred_labels)\n",
        "test_accuracy = accuracy_score(y_test_true_labels, y_test_pred_labels)\n",
        "\n",
        "print(f\"✅ Train Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "print(f\"✅ Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cH6dxZy20m2W",
        "outputId": "56d98e07-8e6c-4e88-ae54-ee2fcc7574bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "🔍 Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.91      0.91        43\n",
            "           1       0.93      0.90      0.92        63\n",
            "           2       0.86      0.83      0.84        71\n",
            "           3       0.80      0.89      0.84        71\n",
            "           4       1.00      0.93      0.96        81\n",
            "           5       0.92      0.78      0.85        93\n",
            "           6       0.87      0.95      0.91        84\n",
            "           7       0.87      0.97      0.92        70\n",
            "\n",
            "    accuracy                           0.89       576\n",
            "   macro avg       0.89      0.90      0.89       576\n",
            "weighted avg       0.90      0.89      0.89       576\n",
            "\n",
            "✅ Train Accuracy: 100.00%\n",
            "✅ Test Accuracy: 89.24%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model_cnn = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.001), input_shape=(40, 130, 1)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Dense(y_encoded.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0003)  # Slower learning rate helps reduce overfitting\n",
        "\n",
        "model_cnn.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "\n",
        "history = model_cnn.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=60,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stop]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BA-BxMuB1lPj",
        "outputId": "2415e019-ab82-4e9e-a1c8-447596040277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.2041 - loss: 3.0754 - val_accuracy: 0.2413 - val_loss: 2.2277\n",
            "Epoch 2/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2565 - loss: 2.1576 - val_accuracy: 0.2882 - val_loss: 2.0677\n",
            "Epoch 3/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.3070 - loss: 2.0145 - val_accuracy: 0.2899 - val_loss: 1.9798\n",
            "Epoch 4/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.3681 - loss: 1.9012 - val_accuracy: 0.4444 - val_loss: 1.8189\n",
            "Epoch 5/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.3884 - loss: 1.8277 - val_accuracy: 0.4931 - val_loss: 1.7161\n",
            "Epoch 6/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4208 - loss: 1.7394 - val_accuracy: 0.5382 - val_loss: 1.6179\n",
            "Epoch 7/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4609 - loss: 1.5990 - val_accuracy: 0.5052 - val_loss: 1.5925\n",
            "Epoch 8/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4762 - loss: 1.5590 - val_accuracy: 0.5538 - val_loss: 1.4827\n",
            "Epoch 9/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4980 - loss: 1.4727 - val_accuracy: 0.6250 - val_loss: 1.3869\n",
            "Epoch 10/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5065 - loss: 1.4408 - val_accuracy: 0.6545 - val_loss: 1.3147\n",
            "Epoch 11/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5389 - loss: 1.3498 - val_accuracy: 0.6476 - val_loss: 1.2989\n",
            "Epoch 12/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5433 - loss: 1.3395 - val_accuracy: 0.6424 - val_loss: 1.2388\n",
            "Epoch 13/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5720 - loss: 1.2767 - val_accuracy: 0.6927 - val_loss: 1.1623\n",
            "Epoch 14/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5673 - loss: 1.2601 - val_accuracy: 0.7135 - val_loss: 1.1262\n",
            "Epoch 15/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5961 - loss: 1.1848 - val_accuracy: 0.7188 - val_loss: 1.0750\n",
            "Epoch 16/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6156 - loss: 1.1403 - val_accuracy: 0.7205 - val_loss: 1.0124\n",
            "Epoch 17/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6275 - loss: 1.1205 - val_accuracy: 0.7552 - val_loss: 0.9443\n",
            "Epoch 18/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6464 - loss: 1.0651 - val_accuracy: 0.7882 - val_loss: 0.8862\n",
            "Epoch 19/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6370 - loss: 1.0637 - val_accuracy: 0.7743 - val_loss: 0.8600\n",
            "Epoch 20/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6815 - loss: 0.9317 - val_accuracy: 0.8021 - val_loss: 0.7901\n",
            "Epoch 21/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6854 - loss: 0.9370 - val_accuracy: 0.8160 - val_loss: 0.7828\n",
            "Epoch 22/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7114 - loss: 0.8766 - val_accuracy: 0.8368 - val_loss: 0.7296\n",
            "Epoch 23/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7323 - loss: 0.8644 - val_accuracy: 0.8038 - val_loss: 0.7519\n",
            "Epoch 24/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7192 - loss: 0.8403 - val_accuracy: 0.8403 - val_loss: 0.6875\n",
            "Epoch 25/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7684 - loss: 0.7588 - val_accuracy: 0.8698 - val_loss: 0.6229\n",
            "Epoch 26/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7555 - loss: 0.7508 - val_accuracy: 0.8681 - val_loss: 0.6031\n",
            "Epoch 27/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7778 - loss: 0.7235 - val_accuracy: 0.8542 - val_loss: 0.5934\n",
            "Epoch 28/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7820 - loss: 0.7119 - val_accuracy: 0.8819 - val_loss: 0.5600\n",
            "Epoch 29/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7947 - loss: 0.6671 - val_accuracy: 0.8785 - val_loss: 0.5404\n",
            "Epoch 30/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8033 - loss: 0.6504 - val_accuracy: 0.8889 - val_loss: 0.5414\n",
            "Epoch 31/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8103 - loss: 0.6447 - val_accuracy: 0.8854 - val_loss: 0.5513\n",
            "Epoch 32/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8238 - loss: 0.5993 - val_accuracy: 0.9028 - val_loss: 0.4736\n",
            "Epoch 33/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8172 - loss: 0.6166 - val_accuracy: 0.8976 - val_loss: 0.5122\n",
            "Epoch 34/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8354 - loss: 0.5648 - val_accuracy: 0.9010 - val_loss: 0.4896\n",
            "Epoch 35/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8480 - loss: 0.5505 - val_accuracy: 0.8958 - val_loss: 0.4991\n",
            "Epoch 36/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8384 - loss: 0.5372 - val_accuracy: 0.9028 - val_loss: 0.4647\n",
            "Epoch 37/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8588 - loss: 0.5232 - val_accuracy: 0.8941 - val_loss: 0.5000\n",
            "Epoch 38/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8653 - loss: 0.5119 - val_accuracy: 0.9010 - val_loss: 0.4907\n",
            "Epoch 39/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8660 - loss: 0.4910 - val_accuracy: 0.8976 - val_loss: 0.4898\n",
            "Epoch 40/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8930 - loss: 0.4634 - val_accuracy: 0.8802 - val_loss: 0.5483\n",
            "Epoch 41/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8735 - loss: 0.4931 - val_accuracy: 0.9062 - val_loss: 0.4649\n",
            "Epoch 42/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8843 - loss: 0.4628 - val_accuracy: 0.9080 - val_loss: 0.4713\n",
            "Epoch 43/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8664 - loss: 0.4869 - val_accuracy: 0.9288 - val_loss: 0.4520\n",
            "Epoch 44/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8847 - loss: 0.4541 - val_accuracy: 0.9236 - val_loss: 0.4336\n",
            "Epoch 45/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8963 - loss: 0.4444 - val_accuracy: 0.9253 - val_loss: 0.4246\n",
            "Epoch 46/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8930 - loss: 0.4279 - val_accuracy: 0.9149 - val_loss: 0.4176\n",
            "Epoch 47/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8978 - loss: 0.4183 - val_accuracy: 0.9167 - val_loss: 0.4410\n",
            "Epoch 48/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9067 - loss: 0.4127 - val_accuracy: 0.9358 - val_loss: 0.4069\n",
            "Epoch 49/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9025 - loss: 0.4218 - val_accuracy: 0.9236 - val_loss: 0.4796\n",
            "Epoch 50/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9096 - loss: 0.4119 - val_accuracy: 0.9184 - val_loss: 0.4427\n",
            "Epoch 51/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9140 - loss: 0.3998 - val_accuracy: 0.9340 - val_loss: 0.4541\n",
            "Epoch 52/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9048 - loss: 0.4203 - val_accuracy: 0.9201 - val_loss: 0.4414\n",
            "Epoch 53/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9148 - loss: 0.4008 - val_accuracy: 0.9045 - val_loss: 0.4596\n",
            "Epoch 54/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9186 - loss: 0.3895 - val_accuracy: 0.9201 - val_loss: 0.4499\n",
            "Epoch 55/60\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9273 - loss: 0.3638 - val_accuracy: 0.9253 - val_loss: 0.4592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Predict on training and testing data\n",
        "y_train_pred = model_cnn.predict(X_train)\n",
        "y_test_pred = model_cnn.predict(X_test)\n",
        "\n",
        "# Convert one-hot encoded vectors to class labels\n",
        "y_train_true = np.argmax(y_train, axis=1)\n",
        "y_test_true = np.argmax(y_test, axis=1)\n",
        "y_train_pred_labels = np.argmax(y_train_pred, axis=1)\n",
        "y_test_pred_labels = np.argmax(y_test_pred, axis=1)\n",
        "\n",
        "# Accuracy\n",
        "train_accuracy = accuracy_score(y_train_true, y_train_pred_labels)\n",
        "test_accuracy = accuracy_score(y_test_true, y_test_pred_labels)\n",
        "\n",
        "print(f\"✅ Train Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "print(f\"✅ Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Classification report for test set\n",
        "print(\"\\n🔍 Classification Report (Test Set):\")\n",
        "print(classification_report(y_test_true, y_test_pred_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdAOAxqZ1ni6",
        "outputId": "b599c95f-0b17-4810-8723-75404caf8b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "✅ Train Accuracy: 99.96%\n",
            "✅ Test Accuracy: 93.58%\n",
            "\n",
            "🔍 Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.97        43\n",
            "           1       0.97      0.97      0.97        63\n",
            "           2       0.84      0.89      0.86        71\n",
            "           3       0.92      0.92      0.92        71\n",
            "           4       1.00      0.98      0.99        81\n",
            "           5       0.91      0.89      0.90        93\n",
            "           6       0.98      0.95      0.96        84\n",
            "           7       0.93      0.94      0.94        70\n",
            "\n",
            "    accuracy                           0.94       576\n",
            "   macro avg       0.94      0.94      0.94       576\n",
            "weighted avg       0.94      0.94      0.94       576\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model"
      ],
      "metadata": {
        "id": "N6bGaWz-29EJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn.save(\"audio_emotion_model.keras\")\n",
        "print(\"✅ Model saved in native Keras (.keras) format\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qbcz3Q02kd1",
        "outputId": "422c3069-0ceb-4d2d-b429-7566fcf33f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model saved in native Keras (.keras) format\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load the model"
      ],
      "metadata": {
        "id": "BAS1YnF32-6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model_cnn = load_model(\"audio_emotion_model.keras\")\n"
      ],
      "metadata": {
        "id": "hDRFqhwm3AL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VIDEO MODEL**"
      ],
      "metadata": {
        "id": "so5qBjr6qsMJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extraction (Frame-wise)"
      ],
      "metadata": {
        "id": "cWBxxcE188dc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load MobileNetV2 + GAP for feature extraction\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "gap_output = GlobalAveragePooling2D()(base_model.output)\n",
        "model = Model(inputs=base_model.input, outputs=gap_output)\n",
        "\n",
        "max_frames = 60\n",
        "\n",
        "def extract_sequence_features(video_path, max_frames=max_frames):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    count = 0\n",
        "\n",
        "    while count < max_frames and cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        img = cv2.resize(frame, (224, 224))\n",
        "        img = preprocess_input(img)\n",
        "        frames.append(img)\n",
        "        count += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    if len(frames) == 0:\n",
        "        # Return zeros if no frames read\n",
        "        return np.zeros((max_frames, 1280), dtype=np.float32)\n",
        "\n",
        "    frames = np.array(frames)\n",
        "    features = model.predict(frames, verbose=0)  # (num_frames, 1280)\n",
        "\n",
        "    # Pad if less than max_frames\n",
        "    if features.shape[0] < max_frames:\n",
        "        pad_len = max_frames - features.shape[0]\n",
        "        features = np.pad(features, ((0, pad_len), (0, 0)), mode='constant')\n",
        "\n",
        "    return features  # shape: (max_frames, 1280)\n",
        "\n",
        "\n",
        "# Paths\n",
        "violent_path = \"/content/video/Real Life Violence Dataset/Violence\"\n",
        "non_violent_path = \"/content/video/Real Life Violence Dataset/NonViolence\"\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "print(\"Extracting features from Violent videos...\")\n",
        "for video_file in tqdm(os.listdir(violent_path)):\n",
        "    path = os.path.join(violent_path, video_file)\n",
        "    X.append(extract_sequence_features(path))\n",
        "    y.append(1)\n",
        "\n",
        "print(\"Extracting features from Non-Violent videos...\")\n",
        "for video_file in tqdm(os.listdir(non_violent_path)):\n",
        "    path = os.path.join(non_violent_path, video_file)\n",
        "    X.append(extract_sequence_features(path))\n",
        "    y.append(0)\n",
        "\n",
        "X = np.array(X, dtype=np.float32)  # shape: (num_samples, 60, 1280)\n",
        "y = np.array(y)\n",
        "\n",
        "# Save features for later use\n",
        "np.save(\"X_lstm.npy\", X)\n",
        "np.save(\"y_lstm.npy\", y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-NWoKWv9Ak9",
        "outputId": "d4c7e423-a9e5-4362-a532-7bac4e996904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features from Violent videos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [06:52<00:00,  2.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features from Non-Violent videos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [05:45<00:00,  2.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " LSTM Model Training and Evaluation"
      ],
      "metadata": {
        "id": "d0aXl__R9EM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load features\n",
        "X = np.load(\"X_lstm.npy\")\n",
        "y = np.load(\"y_lstm.npy\")\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Build LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    LSTM(64),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping to prevent overfitting\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Evaluate on train set\n",
        "train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
        "print(f\"🎯 Train Accuracy: {train_acc:.4f}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"🎯 Test Accuracy : {test_acc:.4f}\")\n",
        "\n",
        "# Predictions & classification report on test set\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int).reshape(-1)\n",
        "\n",
        "print(\"\\n📊 Classification Report (Test Set):\\n\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57J3U3hy9G2b",
        "outputId": "2aab569c-147b-455b-fa7c-15cc5f1e0864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "90/90 - 8s - 92ms/step - accuracy: 0.8125 - loss: 0.4241 - val_accuracy: 0.9250 - val_loss: 0.3193\n",
            "Epoch 2/50\n",
            "90/90 - 6s - 68ms/step - accuracy: 0.9160 - loss: 0.2187 - val_accuracy: 0.9500 - val_loss: 0.1663\n",
            "Epoch 3/50\n",
            "90/90 - 1s - 13ms/step - accuracy: 0.9333 - loss: 0.1821 - val_accuracy: 0.9375 - val_loss: 0.1998\n",
            "Epoch 4/50\n",
            "90/90 - 2s - 17ms/step - accuracy: 0.9493 - loss: 0.1446 - val_accuracy: 0.9187 - val_loss: 0.2505\n",
            "Epoch 5/50\n",
            "90/90 - 2s - 20ms/step - accuracy: 0.9549 - loss: 0.1244 - val_accuracy: 0.8625 - val_loss: 0.3273\n",
            "Epoch 6/50\n",
            "90/90 - 2s - 22ms/step - accuracy: 0.9528 - loss: 0.1341 - val_accuracy: 0.8438 - val_loss: 0.4221\n",
            "Epoch 7/50\n",
            "90/90 - 1s - 14ms/step - accuracy: 0.9667 - loss: 0.0849 - val_accuracy: 0.8813 - val_loss: 0.3474\n",
            "🎯 Train Accuracy: 0.9413\n",
            "🎯 Test Accuracy : 0.9175\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
            "\n",
            "📊 Classification Report (Test Set):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.86      0.91       200\n",
            "           1       0.87      0.97      0.92       200\n",
            "\n",
            "    accuracy                           0.92       400\n",
            "   macro avg       0.92      0.92      0.92       400\n",
            "weighted avg       0.92      0.92      0.92       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bidirectional LSTM with MobileNetV2 Model"
      ],
      "metadata": {
        "id": "GklYw5JvGTOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "X = np.load(\"X_lstm.npy\")\n",
        "y = np.load(\"y_lstm.npy\")\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Model\n",
        "model = Sequential([\n",
        "    Input(shape=(60, 62720)),\n",
        "    Bidirectional(LSTM(128, return_sequences=False)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile\n",
        "optimizer = Adam(learning_rate=1e-4)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping\n",
        "early_stop = EarlyStopping(patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "train_acc = model.evaluate(X_train, y_train, verbose=0)[1]\n",
        "test_acc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
        "print(f\"\\n🎯 Train Accuracy: {train_acc:.4f}\")\n",
        "print(f\"🎯 Test Accuracy : {test_acc:.4f}\")\n",
        "\n",
        "# Classification Report\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "print(\"\\n📊 Classification Report (Test Set):\\n\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm1s4kqDFAFF",
        "outputId": "c9b6f172-96b6-40e1-98ef-5fcb2aefe84f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "100/100 - 10s - 100ms/step - accuracy: 0.8325 - loss: 0.3721 - val_accuracy: 0.9200 - val_loss: 0.2082\n",
            "Epoch 2/50\n",
            "100/100 - 6s - 63ms/step - accuracy: 0.9344 - loss: 0.1731 - val_accuracy: 0.9450 - val_loss: 0.1497\n",
            "Epoch 3/50\n",
            "100/100 - 6s - 60ms/step - accuracy: 0.9550 - loss: 0.1268 - val_accuracy: 0.9400 - val_loss: 0.2022\n",
            "Epoch 4/50\n",
            "100/100 - 11s - 109ms/step - accuracy: 0.9650 - loss: 0.0934 - val_accuracy: 0.9275 - val_loss: 0.1454\n",
            "Epoch 5/50\n",
            "100/100 - 10s - 96ms/step - accuracy: 0.9669 - loss: 0.0882 - val_accuracy: 0.9500 - val_loss: 0.1477\n",
            "Epoch 6/50\n",
            "100/100 - 11s - 105ms/step - accuracy: 0.9856 - loss: 0.0423 - val_accuracy: 0.9400 - val_loss: 0.1508\n",
            "Epoch 7/50\n",
            "100/100 - 6s - 63ms/step - accuracy: 0.9900 - loss: 0.0298 - val_accuracy: 0.9425 - val_loss: 0.1621\n",
            "Epoch 8/50\n",
            "100/100 - 11s - 106ms/step - accuracy: 0.9800 - loss: 0.0488 - val_accuracy: 0.9550 - val_loss: 0.1252\n",
            "Epoch 9/50\n",
            "100/100 - 9s - 95ms/step - accuracy: 0.9937 - loss: 0.0198 - val_accuracy: 0.9500 - val_loss: 0.1574\n",
            "Epoch 10/50\n",
            "100/100 - 11s - 106ms/step - accuracy: 0.9887 - loss: 0.0278 - val_accuracy: 0.9450 - val_loss: 0.1472\n",
            "Epoch 11/50\n",
            "100/100 - 10s - 102ms/step - accuracy: 0.9937 - loss: 0.0162 - val_accuracy: 0.9450 - val_loss: 0.1728\n",
            "Epoch 12/50\n",
            "100/100 - 10s - 102ms/step - accuracy: 0.9994 - loss: 0.0055 - val_accuracy: 0.9475 - val_loss: 0.1683\n",
            "Epoch 13/50\n",
            "100/100 - 10s - 103ms/step - accuracy: 0.9994 - loss: 0.0060 - val_accuracy: 0.9500 - val_loss: 0.1735\n",
            "\n",
            "🎯 Train Accuracy: 0.9969\n",
            "🎯 Test Accuracy : 0.9550\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
            "\n",
            "📊 Classification Report (Test Set):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.96       200\n",
            "           1       0.96      0.94      0.95       200\n",
            "\n",
            "    accuracy                           0.95       400\n",
            "   macro avg       0.96      0.95      0.95       400\n",
            "weighted avg       0.96      0.95      0.95       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save model"
      ],
      "metadata": {
        "id": "d1Nje5EVHJTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save entire model\n",
        "model.save(\"violence_detection_bilstm.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXBQBmSmHKds",
        "outputId": "6908741f-a1df-45a5-ce81-acaaf359fe0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load model"
      ],
      "metadata": {
        "id": "nPd1rUsvHMQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load model from file\n",
        "model = load_model(\"violence_detection_bilstm.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFDw2NknHN0W",
        "outputId": "2b003d72-f2ba-4d97-dafe-a12be3a1b385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    }
  ]
}